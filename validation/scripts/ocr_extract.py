"""
ocr_extract.py
ä½¿ç”¨ VLM å¯¹æ•°å­¦è¯•å·å›¾ç‰‡è¿›è¡Œç»“æ„åŒ– OCR è¯†åˆ«ã€‚
æ¨¡å‹é€šè¿‡ model_config.py ç»Ÿä¸€ç®¡ç†ï¼Œæ”¯æŒ Ollama / DashScope / OpenAI ä¸€é”®åˆ‡æ¢ã€‚

å¿«é€Ÿåˆ‡æ¢æ¨¡å‹ï¼ˆPowerShellï¼‰ï¼š
  $env:AI_MODEL_PRESET = "ollama-qwen-vl"        # Qwen2.5-VL æœ¬åœ°
  $env:AI_MODEL_PRESET = "ollama-deepseek-ocr"   # DeepSeek-OCR æœ¬åœ°
  $env:AI_MODEL_PRESET = "ollama-gpt-oss"        # GPT-OSS 120B æœ¬åœ°
  $env:AI_MODEL_PRESET = "dashscope"             # é˜¿é‡Œäº‘ï¼ˆéœ€ DASHSCOPE_API_KEYï¼‰
  $env:AI_MODEL_PRESET = "openai"                # OpenAIï¼ˆéœ€ OPENAI_API_KEYï¼‰
"""

import os
import json
import base64
import io
import re
import sys
import random
from pathlib import Path
from tqdm import tqdm

try:
    from PIL import Image
except ImportError:
    print("[ERROR] ç¼ºå°‘ä¾èµ–: Pillow")
    print("è¯·è¿è¡Œ: pip install Pillow")
    sys.exit(1)

try:
    from model_config import get_config, build_client, list_presets
except ImportError:
    # å½“ä½œä¸ºç‹¬ç«‹è„šæœ¬è¿è¡Œæ—¶ï¼Œç¡®ä¿ scripts/ åœ¨ path ä¸­
    sys.path.insert(0, str(Path(__file__).parent))
    from model_config import get_config, build_client, list_presets

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Prompt è®¾è®¡ï¼ˆä¸æ¨¡å‹æ— å…³ï¼Œç»Ÿä¸€ä½¿ç”¨ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°å­¦è¯•å·åˆ†æåŠ©æ‰‹ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä»æ•°å­¦è¯•å·å›¾ç‰‡ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚
è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è§£é‡Šã€‚"""

EXTRACT_PROMPT = """åˆ†ææ•°å­¦è¯•å·å›¾ç‰‡ï¼Œæå–é¢˜ç›®å’Œå­¦ç”Ÿä½œç­”ã€‚

è§„åˆ™ï¼š
1. è¯†åˆ«é¢˜å·ã€é¢˜ç›®å†…å®¹ã€æ‰‹å†™ç­”æ¡ˆã€‚answer_area_typeï¼šè®¡ç®—/å¡«ç©º/é€‰æ‹©/åˆ¤æ–­
2. ç©ºç­”æ¡ˆå¡«"æœªä½œç­”"ã€‚å…¬å¼ç”¨åŸºç¡€ç¬¦å·ï¼ˆx^2, m/2ï¼‰
3. åˆ†æ•°è¦ä»”ç»†è¾¨è®¤åˆ†å­åˆ†æ¯ï¼Œå¦‚ 1/m ä¸è¦å†™æˆ 1/2mã€‚ä¸ç¡®å®šçš„å­—ç¬¦åŠ [?]
4. **å¸¦åˆ†æ•°**ï¼šæ•´æ•°éƒ¨åˆ†å’Œåˆ†æ•°éƒ¨åˆ†ä¹‹é—´ç”¨"åˆ"è¿æ¥ã€‚ä¾‹å¦‚ 18Â³â„â‚„ å†™ä½œ "18åˆ3/4"ï¼Œ1â·â„â‚ˆ å†™ä½œ "1åˆ7/8"ã€‚ç»å¯¹ä¸è¦æŠŠæ•´æ•°å’Œåˆ†æ•°åˆå¹¶å†™æˆ "183/4" æˆ– "17/8"
5. **ä¸¥æ ¼åŒºåˆ†é¢˜ç›®ä¸ç­”é¢˜åŒº**ï¼š
   - è¯•å·ä¸Šé¢˜ç›®æ–‡å­—é€šå¸¸åœ¨å·¦ä¾§/ä¸Šæ–¹ï¼Œç­”é¢˜åŒºï¼ˆæ¨ªçº¿/ç©ºç™½/å¡«ç©ºæ¡†ï¼‰åœ¨å³ä¾§/ä¸‹æ–¹
   - ç­”é¢˜åŒºçš„å†…å®¹å±äº student_answerï¼Œç»ä¸èƒ½æ··å…¥ question_text
   - ä¾‹å¦‚ä¸€è¡Œä¸­å·¦è¾¹æ˜¯é¢˜ç›®"...éƒŠéŠå¾‘å…±åˆ†æˆå¤šå°‘å€‹è·¯æ®µï¼Ÿ"ï¼Œå³è¾¹æ˜¯ç­”é¢˜æ¡†"________å€‹è·¯æ®µ"ï¼Œåˆ™ï¼š
     question_text åªåŒ…å«é—®é¢˜éƒ¨åˆ†ï¼Œstudent_answer å¡«å†™ç­”é¢˜åŒºå†…å®¹æˆ–"æœªä½œç­”"
   - å¦‚æœé¢˜å·åç´§è·Ÿæ¨ªçº¿ï¼ˆå¦‚ "7. ________"ï¼‰ï¼Œé‚£æ•´ä¸ªæ¨ªçº¿åŒºåŸŸæ˜¯å¡«ç©ºçš„ç­”æ¡ˆä½ï¼Œä¸æ˜¯é¢˜ç›®
6. question_bbox/answer_bboxï¼šåŒºåŸŸè¾¹ç•Œæ¡†[å·¦%,ä¸Š%,å³%,ä¸‹%]ï¼ˆå å›¾ç‰‡å®½é«˜çš„ç™¾åˆ†æ¯”0~100ï¼‰

JSONæ ¼å¼è¾“å‡ºï¼š
{
  "questions": [
    {
      "question_id": "ç¬¬Xé¢˜",
      "question_text": "é¢˜ç›®åŸæ–‡ï¼ˆä¸å«ç­”é¢˜åŒºæ¨ªçº¿ï¼‰",
      "student_answer": "æ‰‹å†™ç­”æ¡ˆæˆ–æœªä½œç­”",
      "answer_area_type": "è®¡ç®—",
      "question_bbox": [10,30,60,38],
      "answer_bbox": [65,30,95,38]
    }
  ],
  "page_notes": ""
}"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Mock æ¨¡å¼ï¼ˆæ— éœ€æ¨¡å‹ï¼ŒéªŒè¯ Pipeline å®Œæ•´æµç¨‹ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_MOCK_TEMPLATES = [
    {"question_id": "ç¬¬1é¢˜", "question_text": "è®¡ç®—ï¼š(2x+3)^2 = ?", "student_answer": "4x^2+9", "answer_area_type": "è®¡ç®—"},
    {"question_id": "ç¬¬2é¢˜", "question_text": "åŒ–ç®€ï¼š3x + 2x - x = ?", "student_answer": "4x", "answer_area_type": "è®¡ç®—"},
    {"question_id": "ç¬¬3é¢˜", "question_text": "æ±‚è§£ï¼š2x + 5 = 11ï¼Œx = ?", "student_answer": "3", "answer_area_type": "å¡«ç©º"},
    {"question_id": "ç¬¬4é¢˜", "question_text": "ä¸‹åˆ—å“ªä¸ªæ˜¯è´¨æ•°ï¼ŸA.9  B.11  C.15  D.21", "student_answer": "B", "answer_area_type": "é€‰æ‹©"},
    {"question_id": "ç¬¬5é¢˜", "question_text": "è®¡ç®—ï¼šsqrt(144) = ?", "student_answer": "12", "answer_area_type": "å¡«ç©º"},
    {"question_id": "ç¬¬6é¢˜", "question_text": "ä¸¤æ•°ä¹‹ç§¯ä¸º 48ï¼Œä¹‹å’Œä¸º 14ï¼Œä¸¤æ•°å„ä¸ºï¼Ÿ", "student_answer": "6å’Œ8", "answer_area_type": "è®¡ç®—"},
    {"question_id": "ç¬¬7é¢˜", "question_text": "åˆ¤æ–­ï¼šæ‰€æœ‰å¶æ•°éƒ½æ˜¯åˆæ•°ã€‚ï¼ˆå¯¹/é”™ï¼‰", "student_answer": "é”™", "answer_area_type": "åˆ¤æ–­"},
    {"question_id": "ç¬¬8é¢˜", "question_text": "è®¡ç®—ï¼š5! = ?", "student_answer": "æœªä½œç­”", "answer_area_type": "è®¡ç®—"},
]


def mock_extract_from_image(image_path: Path) -> dict:
    """Mock æ¨¡å¼ï¼šç”Ÿæˆç¡®å®šæ€§å ä½é¢˜ç›®æ•°æ®ï¼Œä¸è°ƒç”¨ä»»ä½•æ¨¡å‹ã€‚"""
    random.seed(hash(str(image_path)))
    n = random.randint(4, 7)
    templates = random.sample(_MOCK_TEMPLATES, min(n, len(_MOCK_TEMPLATES)))
    questions = [dict(t, question_id=f"ç¬¬{i}é¢˜") for i, t in enumerate(templates, 1)]
    return {
        "questions": questions,
        "page_notes": "[MOCK] å ä½æ•°æ®ï¼ŒéçœŸå® OCRã€‚",
    }


# å›¾ç‰‡æœ€å¤§å®½åº¦(åƒç´ ), è¶…è¿‡å°†è‡ªåŠ¨ç¼©æ”¾ã€‚
# Qwen2.5-VL è¦æ±‚å®½é«˜å‡ä¸º 28 çš„å€æ•°ï¼Œé»˜è®¤ 1260 = 28Ã—45
MAX_IMAGE_WIDTH = int(os.environ.get("OCR_MAX_WIDTH", "1260"))
# API å•æ¬¡è°ƒç”¨è¶…æ—¶ç§’æ•°
API_TIMEOUT = int(os.environ.get("OCR_TIMEOUT", "120"))
# GGML 500 é‡è¯•æ—¶ä¾æ¬¡å°è¯•çš„å®½åº¦åˆ—è¡¨ï¼ˆå…¨éƒ¨ä¸º 28 çš„å€æ•°ï¼‰
_RETRY_WIDTHS = [1260, 980, 700]
# è§†è§‰æ¨¡å‹è¦æ±‚çš„å¯¹é½å€æ•°ï¼ˆQwen2.5-VL = 28ï¼‰
_ALIGN_MULTIPLE = 28


def _align_to(val: int, multiple: int = _ALIGN_MULTIPLE) -> int:
    """å°†æ•°å€¼å‘ä¸‹å¯¹é½åˆ° multiple çš„å€æ•°ï¼Œä¿è¯ â‰¥1ã€‚"""
    aligned = (val // multiple) * multiple
    return max(aligned, multiple)


def resize_and_encode(image_path: Path, max_width: int = MAX_IMAGE_WIDTH) -> str:
    """
    è¯»å–å›¾ç‰‡ï¼Œç­‰æ¯”ç¼©æ”¾åå°†å®½é«˜å¯¹é½åˆ° 28 çš„å€æ•°ï¼Œ
    ç„¶åè¿”å› JPEG base64 ç¼–ç å­—ç¬¦ä¸²ã€‚
    å¯¹é½å¯é˜²æ­¢ Qwen2.5-VL å†…éƒ¨ GGML_ASSERT å´©æºƒã€‚
    """
    img = Image.open(image_path)
    w, h = img.size
    # ä¿è¯ max_width æœ¬èº«æ˜¯ 28 çš„å€æ•°
    max_width = _align_to(max_width)
    if w > max_width:
        ratio = max_width / w
        new_w = max_width
        new_h = _align_to(int(h * ratio))
    else:
        new_w = _align_to(w)
        new_h = _align_to(h)
    if (new_w, new_h) != (w, h):
        img = img.resize((new_w, new_h), Image.LANCZOS)
        print(f" [{w}x{h}â†’{new_w}x{new_h}]", end="", flush=True)
    buf = io.BytesIO()
    img.convert("RGB").save(buf, format="JPEG", quality=85)
    return base64.b64encode(buf.getvalue()).decode("utf-8")


# ä¿ç•™åŸ encode_image ä»¥å…¼å®¹ï¼ˆç›´æ¥è¯» PNGï¼Œä¸ç¼©æ”¾ï¼‰
def encode_image(image_path: Path) -> str:
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


def _is_ggml_error(exc: Exception) -> bool:
    """æ£€æµ‹å¼‚å¸¸æ˜¯å¦ä¸º GGML_ASSERT / 500 ç±»é”™è¯¯ï¼ˆå¯é‡è¯•ï¼‰ã€‚"""
    msg = str(exc).lower()
    return "ggml_assert" in msg or "500" in msg


def extract_from_image(client, model: str, image_path: Path) -> dict:
    """
    è°ƒç”¨ VLM å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œé¢˜ç›®è¯†åˆ«ã€‚
    å›¾ç‰‡ä¼šå…ˆç¼©æ”¾å¹¶å¯¹é½åˆ° 28 çš„å€æ•°ï¼Œè½¬ä¸º JPEG ä»¥å‡å°ä¼ è¾“é‡ã€‚
    å¦‚æœé‡åˆ° GGML 500 é”™è¯¯ï¼Œä¼šè‡ªåŠ¨ç”¨æ›´å°çš„å°ºå¯¸é‡è¯•ï¼ˆæœ€å¤š 3 æ¬¡ï¼‰ã€‚
    """
    last_error = None
    for attempt, width in enumerate(_RETRY_WIDTHS):
        if attempt > 0:
            print(f"\n  â†» é‡è¯• #{attempt}ï¼ˆç¼©å°åˆ° {width}pxï¼‰...", end="", flush=True)
        try:
            b64 = resize_and_encode(image_path, max_width=width)
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{b64}",
                                    "detail": "high",
                                },
                            },
                            {"type": "text", "text": EXTRACT_PROMPT},
                        ],
                    },
                ],
                temperature=0.1,
                max_tokens=4096,
                timeout=API_TIMEOUT,
            )
            raw = response.choices[0].message.content.strip()

            # å¤šé˜¶æ®µ JSON æå–
            result = _parse_ocr_json(raw)
            if result is not None:
                return result

            print(f"\n[WARN] JSON è§£æå¤±è´¥ ({image_path.name})")
            return {"questions": [], "page_notes": "JSON è§£æå¤±è´¥ï¼Œéœ€äººå·¥å¤æ ¸"}

        except Exception as e:
            last_error = e
            if _is_ggml_error(e) and attempt < len(_RETRY_WIDTHS) - 1:
                print(f"\n[WARN] GGML/500 é”™è¯¯ï¼Œå‡†å¤‡ç¼©å°å›¾ç‰‡é‡è¯•...", end="", flush=True)
                continue  # å°è¯•ä¸‹ä¸€ä¸ªæ›´å°çš„å°ºå¯¸
            # é GGML é”™è¯¯ æˆ– å·²ç”¨å®Œæ‰€æœ‰é‡è¯•
            break

    # æ‰€æœ‰é‡è¯•å‡å¤±è´¥
    print(f"\n[ERROR] æ¨¡å‹è°ƒç”¨å¤±è´¥ ({image_path.name}): {last_error}")
    return {"questions": [], "page_notes": f"æ¨¡å‹é”™è¯¯ï¼ˆå·²é‡è¯•{len(_RETRY_WIDTHS)}æ¬¡ï¼‰: {str(last_error)[:120]}"}


# ç­”é¢˜åŒºæ¨ªçº¿æ¨¡å¼ï¼šåŒ¹é… "æ•°å­—. ___å•ä½(æœ€å¤š4å­—)" æˆ–æœ«å°¾çš„ "___å•ä½"
# é™åˆ¶å•ä½åç¼€æœ€å¤š4ä¸ªå­—ç¬¦ï¼Œé˜²æ­¢è¯¯åˆ é¢˜ç›®æ­£æ–‡
_BLANK_PATTERN = re.compile(
    r'\s*\d+\.\s*[_â€”â€“\-]{2,}\s*[\u4e00-\u9fff]{0,4}\s*'
    r'|\s*[_â€”â€“\-]{3,}\s*[\u4e00-\u9fff]{0,4}\s*(?=[\sï¼Œã€‚ï¼Ÿ]|$)',
    re.MULTILINE,
)


def _postprocess_questions(data: dict) -> dict:
    """
    OCR åå¤„ç†ï¼šå°†æ³„æ¼åˆ° question_text ä¸­çš„ç­”é¢˜åŒºæ¨ªçº¿å‰¥ç¦»ã€‚
    å¦‚æœ student_answer ä¸º'æœªä½œç­”'ä¸”å‰¥ç¦»å‡ºäº†å•ä½æ–‡å­—ï¼Œæ ‡æ³¨åˆ° page_notesã€‚
    """
    for page in data.get("pages", [data]):  # å…¼å®¹å•é¡µå’Œå¤šé¡µ
        for q in page.get("questions", []):
            qt = q.get("question_text", "")
            match = _BLANK_PATTERN.search(qt)
            if match:
                stripped = match.group().strip()
                # ä» question_text ä¸­ç§»é™¤ç­”é¢˜åŒºæ®‹ç•™
                q["question_text"] = _BLANK_PATTERN.sub("", qt).strip()
    return data


def _parse_ocr_json(raw: str) -> dict | None:
    """å¤šé˜¶æ®µ OCR å“åº” JSON è§£æ"""
    import re as _re

    # 1. ç›´æ¥è§£æ
    try:
        return _postprocess_questions(json.loads(raw))
    except (json.JSONDecodeError, ValueError):
        pass

    # 2. å» markdown
    cleaned = raw
    if "```" in cleaned:
        parts = cleaned.split("```")
        for part in parts:
            c = part.strip()
            if c.startswith("json"):
                c = c[4:].strip()
            if c.startswith("{"):
                try:
                    return _postprocess_questions(json.loads(c))
                except (json.JSONDecodeError, ValueError):
                    cleaned = c
                    break

    # 3. æ­£åˆ™æå– {...}
    match = _re.search(r'\{[\s\S]*\}', cleaned)
    if match:
        try:
            return _postprocess_questions(json.loads(match.group()))
        except (json.JSONDecodeError, ValueError):
            pass

    return None


def run_extraction(
    images_dir: Path,
    output_dir: Path,
    mock: bool = False,
    preset: str | None = None,
) -> list[dict]:
    """
    å¯¹æ‰€æœ‰å›¾ç‰‡è¿è¡Œ OCR æå–ï¼Œè¾“å‡º JSON ç»“æœæ–‡ä»¶ã€‚

    å‚æ•°ï¼š
      images_dir  å›¾ç‰‡æ ¹ç›®å½•ï¼ˆæ¯ä¸ª PDF ä¸€ä¸ªå­ç›®å½•ï¼‰
      output_dir  OCR ç»“æœ JSON è¾“å‡ºç›®å½•
      mock        True = ä½¿ç”¨å ä½æ•°æ®ï¼ˆæ— éœ€æ¨¡å‹ï¼‰
      preset      æŒ‡å®šæ¨¡å‹ presetï¼ŒNone åˆ™è¯»å– AI_MODEL_PRESET ç¯å¢ƒå˜é‡
    """
    if mock:
        print("[INFO] MOCK æ¨¡å¼ â€” å ä½æ•°æ®ï¼Œä¸è°ƒç”¨æ¨¡å‹\n")
        client, model = None, "mock"
    else:
        try:
            cfg = get_config(preset)
        except (ValueError, EnvironmentError) as e:
            print(f"\n{e}")
            print(list_presets())
            sys.exit(1)

        client = build_client(cfg)
        model = cfg.model
        print(f"[INFO] Preset:  {cfg.preset}")
        print(f"[INFO] æè¿°:    {cfg.description}")
        print(f"[INFO] Base URL:{cfg.base_url}")
        print(f"[INFO] Model:   {cfg.model}\n")

    output_dir.mkdir(parents=True, exist_ok=True)
    all_results = []

    for pdf_dir in tqdm(sorted(images_dir.iterdir()), desc="å¤„ç†è¯•å·"):
        if not pdf_dir.is_dir():
            continue

        pdf_name = pdf_dir.name
        pdf_result = {"source_file": pdf_name, "mock_mode": mock, "model": model, "pages": []}

        for img_path in sorted(pdf_dir.glob("page_*.png")):
            page_num = int(img_path.stem.split("_")[1])
            print(f"  {pdf_name}/page_{page_num:03d}...", end="", flush=True)

            page_data = mock_extract_from_image(img_path) if mock else extract_from_image(client, model, img_path)
            page_data["page"] = page_num
            pdf_result["pages"].append(page_data)
            print(f" âœ… {len(page_data.get('questions', []))} é“é¢˜")

        out_path = output_dir / f"{pdf_name}_ocr.json"
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(pdf_result, f, ensure_ascii=False, indent=2)
        all_results.append(pdf_result)
        print(f"  ğŸ’¾ {out_path.name}\n")

    return all_results


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="æ•°å­¦è¯•å· OCR è¯†åˆ«")
    parser.add_argument("--mock", action="store_true", help="ä½¿ç”¨å ä½æ•°æ®ï¼Œä¸è°ƒç”¨æ¨¡å‹")
    parser.add_argument("--preset", default=None, help="æŒ‡å®šæ¨¡å‹ presetï¼ˆè§ model_config.pyï¼‰")
    parser.add_argument("--list-presets", action="store_true", help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨ preset")
    args = parser.parse_args()

    if args.list_presets:
        print(list_presets())
        sys.exit(0)

    project_root = Path(__file__).resolve().parent.parent.parent
    images_dir = project_root / "validation" / "output" / "images"
    output_dir = project_root / "validation" / "output" / "ocr_results"

    if not images_dir.exists():
        print("[ERROR] å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ pdf_to_images.py")
        sys.exit(1)

    run_extraction(images_dir, output_dir, mock=args.mock, preset=args.preset)
