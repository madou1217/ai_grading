"""
ocr_extract.py
ä½¿ç”¨ VLM å¯¹æ•°å­¦è¯•å·å›¾ç‰‡è¿›è¡Œç»“æ„åŒ– OCR è¯†åˆ«ã€‚
æ¨¡å‹é€šè¿‡ model_config.py ç»Ÿä¸€ç®¡ç†ï¼Œæ”¯æŒ Ollama / DashScope / OpenAI ä¸€é”®åˆ‡æ¢ã€‚

å¿«é€Ÿåˆ‡æ¢æ¨¡å‹ï¼ˆPowerShellï¼‰ï¼š
  $env:AI_MODEL_PRESET = "ollama-qwen-vl"        # Qwen2.5-VL æœ¬åœ°
  $env:AI_MODEL_PRESET = "ollama-deepseek-ocr"   # DeepSeek-OCR æœ¬åœ°
  $env:AI_MODEL_PRESET = "ollama-gpt-oss"        # GPT-OSS 120B æœ¬åœ°
  $env:AI_MODEL_PRESET = "dashscope"             # é˜¿é‡Œäº‘ï¼ˆéœ€ DASHSCOPE_API_KEYï¼‰
  $env:AI_MODEL_PRESET = "openai"                # OpenAIï¼ˆéœ€ OPENAI_API_KEYï¼‰
"""

import os
import json
import base64
import io
import sys
import random
from pathlib import Path
from tqdm import tqdm

try:
    from PIL import Image
except ImportError:
    print("[ERROR] ç¼ºå°‘ä¾èµ–: Pillow")
    print("è¯·è¿è¡Œ: pip install Pillow")
    sys.exit(1)

try:
    from model_config import get_config, build_client, list_presets
except ImportError:
    # å½“ä½œä¸ºç‹¬ç«‹è„šæœ¬è¿è¡Œæ—¶ï¼Œç¡®ä¿ scripts/ åœ¨ path ä¸­
    sys.path.insert(0, str(Path(__file__).parent))
    from model_config import get_config, build_client, list_presets

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Prompt è®¾è®¡ï¼ˆä¸æ¨¡å‹æ— å…³ï¼Œç»Ÿä¸€ä½¿ç”¨ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°å­¦è¯•å·åˆ†æåŠ©æ‰‹ã€‚
ä½ çš„ä»»åŠ¡æ˜¯ä»æ•°å­¦è¯•å·å›¾ç‰‡ä¸­æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚
è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚çš„ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è§£é‡Šã€‚"""

EXTRACT_PROMPT = """åˆ†ææ•°å­¦è¯•å·å›¾ç‰‡ï¼Œæå–é¢˜ç›®å’Œå­¦ç”Ÿä½œç­”ã€‚

è§„åˆ™ï¼š
1. è¯†åˆ«é¢˜å·ã€é¢˜ç›®å†…å®¹ã€æ‰‹å†™ç­”æ¡ˆã€‚answer_area_typeï¼šè®¡ç®—/å¡«ç©º/é€‰æ‹©/åˆ¤æ–­
2. ç©ºç­”æ¡ˆå¡«"æœªä½œç­”"ã€‚å…¬å¼ç”¨åŸºç¡€ç¬¦å·ï¼ˆx^2, m/2ï¼‰
3. åˆ†æ•°è¦ä»”ç»†è¾¨è®¤åˆ†å­åˆ†æ¯ï¼Œå¦‚ 1/m ä¸è¦å†™æˆ 1/2mã€‚ä¸ç¡®å®šçš„å­—ç¬¦åŠ [?]
4. question_bbox/answer_bboxï¼šåŒºåŸŸè¾¹ç•Œæ¡†[å·¦%,ä¸Š%,å³%,ä¸‹%]ï¼ˆå å›¾ç‰‡å®½é«˜çš„ç™¾åˆ†æ¯”0~100ï¼‰

JSONæ ¼å¼è¾“å‡ºï¼š
{
  "questions": [
    {
      "question_id": "ç¬¬Xé¢˜",
      "question_text": "é¢˜ç›®åŸæ–‡",
      "student_answer": "æ‰‹å†™ç­”æ¡ˆ",
      "answer_area_type": "è®¡ç®—",
      "question_bbox": [10,30,60,38],
      "answer_bbox": [65,30,95,38]
    }
  ],
  "page_notes": ""
}"""

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Mock æ¨¡å¼ï¼ˆæ— éœ€æ¨¡å‹ï¼ŒéªŒè¯ Pipeline å®Œæ•´æµç¨‹ï¼‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_MOCK_TEMPLATES = [
    {"question_id": "ç¬¬1é¢˜", "question_text": "è®¡ç®—ï¼š(2x+3)^2 = ?", "student_answer": "4x^2+9", "answer_area_type": "è®¡ç®—"},
    {"question_id": "ç¬¬2é¢˜", "question_text": "åŒ–ç®€ï¼š3x + 2x - x = ?", "student_answer": "4x", "answer_area_type": "è®¡ç®—"},
    {"question_id": "ç¬¬3é¢˜", "question_text": "æ±‚è§£ï¼š2x + 5 = 11ï¼Œx = ?", "student_answer": "3", "answer_area_type": "å¡«ç©º"},
    {"question_id": "ç¬¬4é¢˜", "question_text": "ä¸‹åˆ—å“ªä¸ªæ˜¯è´¨æ•°ï¼ŸA.9  B.11  C.15  D.21", "student_answer": "B", "answer_area_type": "é€‰æ‹©"},
    {"question_id": "ç¬¬5é¢˜", "question_text": "è®¡ç®—ï¼šsqrt(144) = ?", "student_answer": "12", "answer_area_type": "å¡«ç©º"},
    {"question_id": "ç¬¬6é¢˜", "question_text": "ä¸¤æ•°ä¹‹ç§¯ä¸º 48ï¼Œä¹‹å’Œä¸º 14ï¼Œä¸¤æ•°å„ä¸ºï¼Ÿ", "student_answer": "6å’Œ8", "answer_area_type": "è®¡ç®—"},
    {"question_id": "ç¬¬7é¢˜", "question_text": "åˆ¤æ–­ï¼šæ‰€æœ‰å¶æ•°éƒ½æ˜¯åˆæ•°ã€‚ï¼ˆå¯¹/é”™ï¼‰", "student_answer": "é”™", "answer_area_type": "åˆ¤æ–­"},
    {"question_id": "ç¬¬8é¢˜", "question_text": "è®¡ç®—ï¼š5! = ?", "student_answer": "æœªä½œç­”", "answer_area_type": "è®¡ç®—"},
]


def mock_extract_from_image(image_path: Path) -> dict:
    """Mock æ¨¡å¼ï¼šç”Ÿæˆç¡®å®šæ€§å ä½é¢˜ç›®æ•°æ®ï¼Œä¸è°ƒç”¨ä»»ä½•æ¨¡å‹ã€‚"""
    random.seed(hash(str(image_path)))
    n = random.randint(4, 7)
    templates = random.sample(_MOCK_TEMPLATES, min(n, len(_MOCK_TEMPLATES)))
    questions = [dict(t, question_id=f"ç¬¬{i}é¢˜") for i, t in enumerate(templates, 1)]
    return {
        "questions": questions,
        "page_notes": "[MOCK] å ä½æ•°æ®ï¼ŒéçœŸå® OCRã€‚",
    }


# å›¾ç‰‡æœ€å¤§å®½åº¦(åƒç´ ), è¶…è¿‡å°†è‡ªåŠ¨ç¼©æ”¾ã€‚
# 7B æ¨¡å‹å»ºè®® 1024~1280pxï¼Œå¤§æ¨¡å‹å¯é€‚å½“è°ƒé«˜
MAX_IMAGE_WIDTH = int(os.environ.get("OCR_MAX_WIDTH", "1280"))
# API å•æ¬¡è°ƒç”¨è¶…æ—¶ç§’æ•°
API_TIMEOUT = int(os.environ.get("OCR_TIMEOUT", "120"))


def resize_and_encode(image_path: Path, max_width: int = MAX_IMAGE_WIDTH) -> str:
    """
    è¯»å–å›¾ç‰‡ï¼Œå¦‚æœå®½åº¦è¶…è¿‡ max_width åˆ™ç­‰æ¯”ä¾‹ç¼©æ”¾ï¼Œ
    ç„¶åè¿”å› JPEG base64 ç¼–ç å­—ç¬¦ä¸²ã€‚
    JPEG å¸¸å¸¸æ¯” PNG å° 3~5 å€ï¼Œæ˜¾è‘—å‡å°‘ä¼ è¾“é‡ã€‚
    """
    img = Image.open(image_path)
    w, h = img.size
    if w > max_width:
        ratio = max_width / w
        img = img.resize((max_width, int(h * ratio)), Image.LANCZOS)
        print(f" [{w}x{h}â†’{img.size[0]}x{img.size[1]}]", end="", flush=True)
    buf = io.BytesIO()
    img.convert("RGB").save(buf, format="JPEG", quality=85)
    return base64.b64encode(buf.getvalue()).decode("utf-8")


# ä¿ç•™åŸ encode_image ä»¥å…¼å®¹ï¼ˆç›´æ¥è¯» PNGï¼Œä¸ç¼©æ”¾ï¼‰
def encode_image(image_path: Path) -> str:
    with open(image_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


def extract_from_image(client, model: str, image_path: Path) -> dict:
    """
    è°ƒç”¨ VLM å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œé¢˜ç›®è¯†åˆ«ã€‚
    å›¾ç‰‡ä¼šå…ˆç¼©æ”¾åˆ° MAX_IMAGE_WIDTH å®½å¹¶è½¬ä¸º JPEGï¼Œæ˜¾è‘—å‡å°‘çš®è·å’Œå»¶è¿Ÿã€‚
    API è°ƒç”¨è¶…æ—¶ä¸º API_TIMEOUT ç§’ã€‚
    """
    b64 = resize_and_encode(image_path)  # è‡ªåŠ¨ç¼©æ”¾ + JPEG å‹ç¼©
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{b64}",
                                "detail": "high",
                            },
                        },
                        {"type": "text", "text": EXTRACT_PROMPT},
                    ],
                },
            ],
            temperature=0.1,
            max_tokens=4096,
            timeout=API_TIMEOUT,  # é˜²æ­¢æ— é™å¡æ­»
        )
        raw = response.choices[0].message.content.strip()

        # å¤šé˜¶æ®µ JSON æå–
        result = _parse_ocr_json(raw)
        if result is not None:
            return result

        print(f"\n[WARN] JSON è§£æå¤±è´¥ ({image_path.name})")
        return {"questions": [], "page_notes": "JSON è§£æå¤±è´¥ï¼Œéœ€äººå·¥å¤æ ¸"}

    except Exception as e:
        print(f"\n[ERROR] æ¨¡å‹è°ƒç”¨å¤±è´¥ ({image_path.name}): {e}")
        return {"questions": [], "page_notes": f"æ¨¡å‹é”™è¯¯: {str(e)[:120]}"}


def _parse_ocr_json(raw: str) -> dict | None:
    """å¤šé˜¶æ®µ OCR å“åº” JSON è§£æ"""
    import re as _re

    # 1. ç›´æ¥è§£æ
    try:
        return json.loads(raw)
    except (json.JSONDecodeError, ValueError):
        pass

    # 2. å» markdown
    cleaned = raw
    if "```" in cleaned:
        parts = cleaned.split("```")
        for part in parts:
            c = part.strip()
            if c.startswith("json"):
                c = c[4:].strip()
            if c.startswith("{"):
                try:
                    return json.loads(c)
                except (json.JSONDecodeError, ValueError):
                    cleaned = c
                    break

    # 3. æ­£åˆ™æå– {...}
    match = _re.search(r'\{[\s\S]*\}', cleaned)
    if match:
        try:
            return json.loads(match.group())
        except (json.JSONDecodeError, ValueError):
            pass

    return None


def run_extraction(
    images_dir: Path,
    output_dir: Path,
    mock: bool = False,
    preset: str | None = None,
) -> list[dict]:
    """
    å¯¹æ‰€æœ‰å›¾ç‰‡è¿è¡Œ OCR æå–ï¼Œè¾“å‡º JSON ç»“æœæ–‡ä»¶ã€‚

    å‚æ•°ï¼š
      images_dir  å›¾ç‰‡æ ¹ç›®å½•ï¼ˆæ¯ä¸ª PDF ä¸€ä¸ªå­ç›®å½•ï¼‰
      output_dir  OCR ç»“æœ JSON è¾“å‡ºç›®å½•
      mock        True = ä½¿ç”¨å ä½æ•°æ®ï¼ˆæ— éœ€æ¨¡å‹ï¼‰
      preset      æŒ‡å®šæ¨¡å‹ presetï¼ŒNone åˆ™è¯»å– AI_MODEL_PRESET ç¯å¢ƒå˜é‡
    """
    if mock:
        print("[INFO] MOCK æ¨¡å¼ â€” å ä½æ•°æ®ï¼Œä¸è°ƒç”¨æ¨¡å‹\n")
        client, model = None, "mock"
    else:
        try:
            cfg = get_config(preset)
        except (ValueError, EnvironmentError) as e:
            print(f"\n{e}")
            print(list_presets())
            sys.exit(1)

        client = build_client(cfg)
        model = cfg.model
        print(f"[INFO] Preset:  {cfg.preset}")
        print(f"[INFO] æè¿°:    {cfg.description}")
        print(f"[INFO] Base URL:{cfg.base_url}")
        print(f"[INFO] Model:   {cfg.model}\n")

    output_dir.mkdir(parents=True, exist_ok=True)
    all_results = []

    for pdf_dir in tqdm(sorted(images_dir.iterdir()), desc="å¤„ç†è¯•å·"):
        if not pdf_dir.is_dir():
            continue

        pdf_name = pdf_dir.name
        pdf_result = {"source_file": pdf_name, "mock_mode": mock, "model": model, "pages": []}

        for img_path in sorted(pdf_dir.glob("page_*.png")):
            page_num = int(img_path.stem.split("_")[1])
            print(f"  {pdf_name}/page_{page_num:03d}...", end="", flush=True)

            page_data = mock_extract_from_image(img_path) if mock else extract_from_image(client, model, img_path)
            page_data["page"] = page_num
            pdf_result["pages"].append(page_data)
            print(f" âœ… {len(page_data.get('questions', []))} é“é¢˜")

        out_path = output_dir / f"{pdf_name}_ocr.json"
        with open(out_path, "w", encoding="utf-8") as f:
            json.dump(pdf_result, f, ensure_ascii=False, indent=2)
        all_results.append(pdf_result)
        print(f"  ğŸ’¾ {out_path.name}\n")

    return all_results


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="æ•°å­¦è¯•å· OCR è¯†åˆ«")
    parser.add_argument("--mock", action="store_true", help="ä½¿ç”¨å ä½æ•°æ®ï¼Œä¸è°ƒç”¨æ¨¡å‹")
    parser.add_argument("--preset", default=None, help="æŒ‡å®šæ¨¡å‹ presetï¼ˆè§ model_config.pyï¼‰")
    parser.add_argument("--list-presets", action="store_true", help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨ preset")
    args = parser.parse_args()

    if args.list_presets:
        print(list_presets())
        sys.exit(0)

    project_root = Path(__file__).resolve().parent.parent.parent
    images_dir = project_root / "validation" / "output" / "images"
    output_dir = project_root / "validation" / "output" / "ocr_results"

    if not images_dir.exists():
        print("[ERROR] å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ pdf_to_images.py")
        sys.exit(1)

    run_extraction(images_dir, output_dir, mock=args.mock, preset=args.preset)
